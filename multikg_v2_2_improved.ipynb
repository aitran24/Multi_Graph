{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8d97135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing T1003.002...\n",
      "Parsing windows-sysmon.log...\n",
      "Parsed 7016 events\n",
      "After filtering: 6695 events (removed 321 noise)\n",
      "Ancestry map: 240 parent-child relationships\n",
      "Attack subgraph: 19 events from 20 malicious processes\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\security\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E700-000000007F01} -> CREATED_FILE -> File:cdef9e788293643a\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\system\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E600-000000007F01} -> CREATED_FILE -> File:51ebcbb27fd690e5\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\sam\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E500-000000007F01} -> CREATED_FILE -> File:05b9ebacd97be5dc\n",
      "[DEBUG] Creating file node for reg save: %%temp%%\\sam\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E400-000000007F01} -> CREATED_FILE -> File:6eaa5a85f55e1c7e\n",
      "  Post-processing removed: 1 nodes, 1 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "\n",
      "Graph Statistics (after post-processing):\n",
      "  Nodes: 26\n",
      "  Edges: 23\n",
      "  Orphan Edges: 0\n",
      "  Isolated Nodes: 0\n",
      "  Node Types: {'Process': 20, 'File': 5, 'Registry': 1}\n",
      "  Edge Types: {'CREATED': 17, 'CREATED_FILE': 5, 'QUERY_REGISTRY': 1}\n",
      "Saved to d:\\nckh\\auditlog\\output\\T1003.002_graph_v2.2.json\n"
     ]
    }
   ],
   "source": [
    "# Test T1003.002 with debug\n",
    "result = process_technique_v2_2('T1003.002', BASE_DIR, CONFIG_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e18be2",
   "metadata": {},
   "source": [
    "# MultiKG v2.2 - Advanced Provenance Graph Construction\n",
    "\n",
    "**Research-Grade Improvements:**\n",
    "1. **SHA-256 Compression** - Full command line hash prevents false grouping\n",
    "2. **Artifact Filtering** - Removes PSScriptPolicyTest and temp file noise\n",
    "3. **Self-Loop Removal** - Eliminates redundant process self-access edges\n",
    "4. **File Aggregation** - Groups PowerShell artifacts and random temp files\n",
    "5. **Edge Deduplication** - Tracks repeated accesses with counters\n",
    "6. **Path Generalization** - Environment variables for cross-system fusion\n",
    "\n",
    "**Based on:** MultiKG Algorithm 4 with extensions for noise reduction and compression robustness\n",
    "\n",
    "**Key Metrics:**\n",
    "- Target: 60-80 nodes per technique (vs 200+ in v2.1)\n",
    "- Target: 0 orphan edges, 0 isolated nodes\n",
    "- Target: 100% artifact filtering for PSScriptPolicyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c8fdc",
   "metadata": {},
   "source": [
    "## Cell 1: Import Required Libraries and Configuration\n",
    "\n",
    "Import core libraries for parsing, hashing, graph operations, and data processing. Configure base directories and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e55966ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Base directory: d:\\nckh\\auditlog\\atomic_red_team_data\n",
      "Output directory: d:\\nckh\\auditlog\\output\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import hashlib\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path(r\"d:\\nckh\\auditlog\\atomic_red_team_data\")\n",
    "CONFIG_DIR = Path(r\"d:\\nckh\\auditlog\\configs\")\n",
    "OUTPUT_DIR = Path(r\"d:\\nckh\\auditlog\\output\")\n",
    "\n",
    "# Load global configuration\n",
    "def load_global_whitelist() -> Dict:\n",
    "    with open(CONFIG_DIR / 'global_whitelist.json', 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_technique_config(technique_id: str) -> Dict:\n",
    "    with open(CONFIG_DIR / f'{technique_id}.json', 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_metadata(technique_dir: Path) -> Optional[Dict]:\n",
    "    \"\"\"Load metadata.json to get attack execution details.\"\"\"\n",
    "    # Search for metadata.json in subdirectories\n",
    "    for metadata_file in technique_dir.rglob('metadata.json'):\n",
    "        try:\n",
    "            with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading metadata: {e}\")\n",
    "    return None\n",
    "\n",
    "GLOBAL_CONFIG = load_global_whitelist()\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf33c3",
   "metadata": {},
   "source": [
    "## Cell 2: XML Parser and Event Extraction\n",
    "\n",
    "Parse Sysmon event logs from XML format. Extract event data including EventID, timestamps, and all Data elements. Handle XML parsing errors gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e5f3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML parser defined\n"
     ]
    }
   ],
   "source": [
    "def parse_sysmon_streaming(log_path: Path, start_time: Optional[str] = None, end_time: Optional[str] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse Sysmon event logs using streaming XML parser.\n",
    "    Handles large log files efficiently by processing events one at a time.\n",
    "    Includes Temporal Filtering based on metadata start/end times.\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    \n",
    "    # Convert string times to datetime for comparison\n",
    "    dt_start = None\n",
    "    dt_end = None\n",
    "    if start_time:\n",
    "        try:\n",
    "            dt_start = datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n",
    "        except: pass\n",
    "    if end_time:\n",
    "        try:\n",
    "            dt_end = datetime.fromisoformat(end_time.replace('Z', '+00:00'))\n",
    "        except: pass\n",
    "\n",
    "    with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    event_pattern = re.compile(r'<Event[^>]*>.*?</Event>', re.DOTALL)\n",
    "    \n",
    "    for match in event_pattern.finditer(content):\n",
    "        event_xml = match.group(0)\n",
    "        \n",
    "        try:\n",
    "            root = ET.fromstring(event_xml)\n",
    "            \n",
    "            system = root.find('.//{http://schemas.microsoft.com/win/2004/08/events/event}System')\n",
    "            if system is None:\n",
    "                continue\n",
    "            \n",
    "            event_id_elem = system.find('.//{http://schemas.microsoft.com/win/2004/08/events/event}EventID')\n",
    "            time_created_elem = system.find('.//{http://schemas.microsoft.com/win/2004/08/events/event}TimeCreated')\n",
    "            \n",
    "            if event_id_elem is None or time_created_elem is None:\n",
    "                continue\n",
    "            \n",
    "            sys_time_str = time_created_elem.get('SystemTime', '')\n",
    "            \n",
    "            # Temporal Filtering\n",
    "            if dt_start and dt_end and sys_time_str:\n",
    "                try:\n",
    "                    dt_event = datetime.fromisoformat(sys_time_str.replace('Z', '+00:00'))\n",
    "                    # Add a small buffer (e.g., 1 second) to account for clock skew or logging delay\n",
    "                    # But strictly speaking, we should respect the window.\n",
    "                    # Let's add a 5-second buffer before start and after end to be safe\n",
    "                    buffer = 5.0 \n",
    "                    if not (dt_start.timestamp() - buffer <= dt_event.timestamp() <= dt_end.timestamp() + buffer):\n",
    "                        continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            event_data = {\n",
    "                'EventID': int(event_id_elem.text),\n",
    "                'SystemTime': sys_time_str\n",
    "            }\n",
    "            \n",
    "            event_data_elem = root.find('.//{http://schemas.microsoft.com/win/2004/08/events/event}EventData')\n",
    "            if event_data_elem is not None:\n",
    "                for data_elem in event_data_elem.findall('.//{http://schemas.microsoft.com/win/2004/08/events/event}Data'):\n",
    "                    name = data_elem.get('Name')\n",
    "                    value = data_elem.text or ''\n",
    "                    if name:\n",
    "                        event_data[name] = value\n",
    "            \n",
    "            events.append(event_data)\n",
    "                \n",
    "        except ET.ParseError:\n",
    "            continue\n",
    "    \n",
    "    return events\n",
    "\n",
    "print(\"XML parser defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007715e",
   "metadata": {},
   "source": [
    "## Cell 3: Enhanced Filtering with Improved Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1d6f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced filtering v2.2.1 defined\n"
     ]
    }
   ],
   "source": [
    "def filter_splunk_noise(events: List[Dict], config: Dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Remove benign noise using global + technique-specific whitelists.\n",
    "    v2.2.1: Aggressive filtering for monitoring agents and system infrastructure.\n",
    "    \"\"\"\n",
    "    global_whitelist = config.get('global_whitelist', [])\n",
    "    local_whitelist = config.get('process_whitelist', [])\n",
    "    combined_whitelist = set(global_whitelist + local_whitelist)\n",
    "    \n",
    "    artifact_patterns = config.get('artifact_patterns', [])\n",
    "    ignore_processes = config.get('ignore_processes', [])\n",
    "    low_priority_procs = config.get('low_priority_system_processes', [])\n",
    "    \n",
    "    filtered = []\n",
    "    for event in events:\n",
    "        image = event.get('Image', '').lower()\n",
    "        parent_image = event.get('ParentImage', '').lower()\n",
    "        \n",
    "        # Skip monitoring agents (Splunk, SSM, WMI)\n",
    "        if any(proc.lower() in image for proc in ignore_processes):\n",
    "            continue\n",
    "        \n",
    "        # Skip low-priority system processes UNLESS they're the target\n",
    "        image_name = Path(image).name if image else ''\n",
    "        if image_name in [p.lower() for p in low_priority_procs]:\n",
    "            # Allow if parent is suspicious (non-system)\n",
    "            parent_name = Path(parent_image).name if parent_image else ''\n",
    "            if parent_name not in [p.lower() for p in low_priority_procs]:\n",
    "                # System proc spawned by user proc → keep\n",
    "                pass\n",
    "            else:\n",
    "                # System-to-system → skip\n",
    "                continue\n",
    "        \n",
    "        # Filter artifacts (PSScriptPolicyTest, temp files)\n",
    "        if event.get('EventID') == 11:  # FileCreate\n",
    "            target_file = event.get('TargetFilename', '')\n",
    "            is_artifact = any(re.search(pattern, target_file, re.IGNORECASE) for pattern in artifact_patterns)\n",
    "            if is_artifact:\n",
    "                continue\n",
    "        \n",
    "        # Standard whitelist check\n",
    "        is_whitelisted = any(w in image for w in combined_whitelist)\n",
    "        parent_is_whitelisted = any(w in parent_image for w in combined_whitelist)\n",
    "        \n",
    "        if not is_whitelisted or not parent_is_whitelisted:\n",
    "            filtered.append(event)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "print(\"Enhanced filtering v2.2.1 defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f04378",
   "metadata": {},
   "source": [
    "## Cell 4: Ancestry Tracking with GUID Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c0d991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ancestry tracking defined\n"
     ]
    }
   ],
   "source": [
    "def find_ancestry(events: List[Dict]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Map process GUIDs to parent GUIDs for ancestry tracking.\n",
    "    Optimized with GUID mapping for fast lookup.\n",
    "    \"\"\"\n",
    "    guid_map = {}\n",
    "    \n",
    "    for event in events:\n",
    "        if event.get('EventID') == 1:\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            parent_guid = event.get('ParentProcessGuid', '')\n",
    "            \n",
    "            if process_guid and parent_guid:\n",
    "                guid_map[process_guid] = parent_guid\n",
    "    \n",
    "    return guid_map\n",
    "\n",
    "print(\"Ancestry tracking defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac9d27",
   "metadata": {},
   "source": [
    "## Cell 5: Attack Subgraph Extraction (Two-Pass Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "677241e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack extraction v2.2.1 defined\n"
     ]
    }
   ],
   "source": [
    "def extract_attack_subgraph(events: List[Dict], config: Dict, guid_map: Dict[str, str], initial_pid: Optional[str] = None) -> Tuple[List[Dict], set]:\n",
    "    \"\"\"\n",
    "    Two-pass algorithm with improved noise filtering.\n",
    "    v2.2.1: Skip monitoring agents even if in ancestry tree.\n",
    "    v2.3.0: Forward Expansion from InitialPID (Paper Algorithm 1)\n",
    "    \"\"\"\n",
    "    malicious_guids = set()\n",
    "    suspicious_patterns = config.get('suspicious_patterns', [])\n",
    "    focus_processes = config.get('focus_processes', [])\n",
    "    registry_keys = config.get('registry_keys', [])\n",
    "    ignore_processes = config.get('ignore_processes', [])\n",
    "    \n",
    "    if isinstance(suspicious_patterns, dict):\n",
    "        patterns = []\n",
    "        for key, values in suspicious_patterns.items():\n",
    "            if isinstance(values, list):\n",
    "                patterns.extend(values)\n",
    "            else:\n",
    "                patterns.append(values)\n",
    "        suspicious_patterns = patterns\n",
    "    \n",
    "    # --- STRATEGY 1: Forward Expansion from Known InitialPID (Paper Algorithm 1) ---\n",
    "    if initial_pid:\n",
    "        print(f\"[INFO] Using Forward Expansion from InitialPID: {initial_pid}\")\n",
    "        # Find the GUID for the initial PID\n",
    "        # Note: PID can be reused, so we need to be careful. \n",
    "        # But since we already filtered by time, it's safer.\n",
    "        # We look for the first Event 1 with this ProcessId\n",
    "        root_guid = None\n",
    "        for event in events:\n",
    "            if event.get('EventID') == 1 and str(event.get('ProcessId')) == str(initial_pid):\n",
    "                root_guid = event.get('ProcessGuid')\n",
    "                break\n",
    "        \n",
    "        if root_guid:\n",
    "            malicious_guids.add(root_guid)\n",
    "            # BFS Forward Expansion\n",
    "            queue = [root_guid]\n",
    "            while queue:\n",
    "                current_guid = queue.pop(0)\n",
    "                # Find children\n",
    "                for event in events:\n",
    "                    if event.get('EventID') == 1 and event.get('ParentProcessGuid') == current_guid:\n",
    "                        child_guid = event.get('ProcessGuid')\n",
    "                        if child_guid and child_guid not in malicious_guids:\n",
    "                            malicious_guids.add(child_guid)\n",
    "                            queue.append(child_guid)\n",
    "        else:\n",
    "            print(f\"[WARNING] InitialPID {initial_pid} not found in events. Falling back to heuristic detection.\")\n",
    "\n",
    "    # --- STRATEGY 2: Heuristic Detection (Fallback or Supplement) ---\n",
    "    # Even if we have InitialPID, we might miss side-loaded attacks, so we keep this but prioritize the chain.\n",
    "    \n",
    "    # Track file creation for user execution detection\n",
    "    created_files = {}  # {file_path: (creator_guid, timestamp)}\n",
    "    \n",
    "    for event in events:\n",
    "        eid = event.get('EventID')\n",
    "        \n",
    "        # Skip monitoring agents at detection stage\n",
    "        image = event.get('Image', '').lower()\n",
    "        if any(proc.lower() in image for proc in ignore_processes):\n",
    "            continue\n",
    "        \n",
    "        # Track file creation (for T1204 User Execution detection)\n",
    "        if eid == 11:\n",
    "            target_file = event.get('TargetFilename', '').lower()\n",
    "            creator_guid = event.get('ProcessGuid', '')\n",
    "            timestamp = event.get('SystemTime', '')\n",
    "            # Track suspicious file types\n",
    "            suspicious_extensions = ['.bat', '.cmd', '.vbs', '.js', '.jse', '.ps1', \n",
    "                                    '.exe', '.dll', '.scr', '.hta', '.lnk']\n",
    "            if any(target_file.endswith(ext) for ext in suspicious_extensions):\n",
    "                created_files[target_file] = (creator_guid, timestamp)\n",
    "        \n",
    "        if eid == 1:\n",
    "            cmdline = event.get('CommandLine', '').lower()\n",
    "            parent_image = event.get('ParentImage', '').lower()\n",
    "            \n",
    "            if any(pat.lower() in cmdline for pat in suspicious_patterns):\n",
    "                malicious_guids.add(event.get('ProcessGuid', ''))\n",
    "            \n",
    "            if any(proc.lower() in image for proc in focus_processes):\n",
    "                malicious_guids.add(event.get('ProcessGuid', ''))\n",
    "            \n",
    "            # Detect user execution: Process executing recently created suspicious file\n",
    "            # Check if command line references a created file\n",
    "            for created_file, (creator_guid, _) in created_files.items():\n",
    "                if created_file in cmdline:\n",
    "                    # Mark both creator and executor as malicious\n",
    "                    malicious_guids.add(creator_guid)\n",
    "                    malicious_guids.add(event.get('ProcessGuid', ''))\n",
    "            \n",
    "            # Detect user execution: Unusual parent-child relationships\n",
    "            # e.g., notepad.exe -> cmd.exe, explorer.exe -> powershell.exe with script\n",
    "            user_apps = ['notepad.exe', 'wordpad.exe', 'winword.exe', 'excel.exe']\n",
    "            if any(app in parent_image for app in user_apps):\n",
    "                # User app spawning shell/script - likely user execution\n",
    "                if 'cmd.exe' in image or 'powershell.exe' in image or 'wscript.exe' in image:\n",
    "                    malicious_guids.add(event.get('ProcessGuid', ''))\n",
    "        \n",
    "        elif eid == 13:\n",
    "            target_object = event.get('TargetObject', '').lower()\n",
    "            if any(key.lower() in target_object for key in registry_keys):\n",
    "                malicious_guids.add(event.get('ProcessGuid', ''))\n",
    "    \n",
    "    # Expand to ancestors (but skip monitoring agents)\n",
    "    # v2.3.0: Limit ancestry expansion if we have a solid forward chain\n",
    "    if not initial_pid:\n",
    "        expanded_guids = set(malicious_guids)\n",
    "        for guid in malicious_guids:\n",
    "            current = guid\n",
    "            while current in guid_map:\n",
    "                parent = guid_map[current]\n",
    "                \n",
    "                # Check if parent is monitoring agent\n",
    "                parent_event = next((e for e in events if e.get('ProcessGuid') == parent), None)\n",
    "                if parent_event:\n",
    "                    parent_image = parent_event.get('Image', '').lower()\n",
    "                    if any(proc.lower() in parent_image for proc in ignore_processes):\n",
    "                        break  # Stop ancestry expansion\n",
    "                \n",
    "                expanded_guids.add(parent)\n",
    "                current = parent\n",
    "    else:\n",
    "        # If we have initial_pid, we trust the forward chain more.\n",
    "        # But we still might want to see the parent of the root (e.g., Explorer -> PowerShell)\n",
    "        expanded_guids = set(malicious_guids)\n",
    "        # Optional: Add just one level of parent for context\n",
    "        for guid in list(malicious_guids):\n",
    "             if guid in guid_map:\n",
    "                 expanded_guids.add(guid_map[guid])\n",
    "\n",
    "    # Common Process Filtering (Paper Algorithm 1, Line 13)\n",
    "    common_processes = [\n",
    "        'hostname.exe', 'whoami.exe', 'systeminfo.exe',\n",
    "        'ipconfig.exe', 'net.exe', 'netstat.exe'\n",
    "    ]\n",
    "    # Only filter if they are leaf nodes (no children in the malicious set)\n",
    "    # Actually, the paper says \"RemoveCommonProcesses\", implying they are noise if they don't lead to further attacks.\n",
    "    # But often they are the attack (Discovery). We keep them if they are explicitly malicious (matched patterns).\n",
    "    # If they were just pulled in by ancestry, we might drop them.\n",
    "    # For now, we'll trust the pattern matching.\n",
    "    \n",
    "    # Pass 2: Collect events (skip monitoring agents)\n",
    "    attack_events = []\n",
    "    for event in events:\n",
    "        proc_guid = event.get('ProcessGuid', '')\n",
    "        if proc_guid in expanded_guids:\n",
    "            # Final check: skip if event from monitoring agent\n",
    "            image = event.get('Image', '').lower()\n",
    "            if not any(proc.lower() in image for proc in ignore_processes):\n",
    "                attack_events.append(event)\n",
    "    \n",
    "    return attack_events, expanded_guids\n",
    "\n",
    "print(\"Attack extraction v2.2.1 defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e01326",
   "metadata": {},
   "source": [
    "## Cell 6: Path Generalization for Cross-System Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1315e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path generalization v2.2.1 defined\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def aggregate_file_path(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Aggregate artifact and temp files to reduce node explosion.\n",
    "    v2.2.1: More aggressive aggregation for random temp files.\n",
    "    \"\"\"\n",
    "    if not path:\n",
    "        return path\n",
    "    \n",
    "    # Aggregate PSScriptPolicyTest files\n",
    "    if '__PSScriptPolicyTest_' in path:\n",
    "        return '%TEMP%\\\\PSScriptPolicyTest\\\\[Aggregated]'\n",
    "    \n",
    "    # Aggregate random temp files (8-16 hex chars)\n",
    "    if re.search(r'\\\\Temp\\\\[a-z0-9]{8,16}\\.(dll|ps1|cmdline|txt)$', path, re.IGNORECASE):\n",
    "        ext = Path(path).suffix\n",
    "        return f'%TEMP%\\\\[RandomFile{ext}]'\n",
    "    \n",
    "    # Aggregate tmp files (Windows temp naming)\n",
    "    if re.search(r'\\\\Temp\\\\tmp[A-F0-9]{4,8}\\.[^\\\\]+$', path, re.IGNORECASE):\n",
    "        ext = Path(path).suffix\n",
    "        return f'%TEMP%\\\\[TmpFile{ext}]'\n",
    "    \n",
    "    # Aggregate .etl (Event Trace Logs - usually monitoring)\n",
    "    if path.lower().endswith('.etl'):\n",
    "        return '%TEMP%\\\\[EventTrace.etl]'\n",
    "    \n",
    "    # Aggregate Prefetch files\n",
    "    if '\\\\Prefetch\\\\' in path:\n",
    "        return '%WINDIR%\\\\Prefetch\\\\[Aggregated.pf]'\n",
    "    \n",
    "    return path\n",
    "\n",
    "def generalize_path(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Generalize paths for cross-system graph fusion.\n",
    "    Replace user-specific paths with environment variables.\n",
    "    \"\"\"\n",
    "    if not path:\n",
    "        return path\n",
    "    \n",
    "    # First aggregate artifacts\n",
    "    path = aggregate_file_path(path)\n",
    "    \n",
    "    # Replace user paths\n",
    "    path = re.sub(r'C:\\\\Users\\\\[^\\\\]+', '%USER%', path, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Replace temp paths\n",
    "    path = re.sub(r'\\\\AppData\\\\Local\\\\Temp', '%TEMP%', path, flags=re.IGNORECASE)\n",
    "    path = re.sub(r'\\\\Windows\\\\Temp', r'%WINDIR%\\\\Temp', path, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Replace system paths\n",
    "    path = path.replace('C:\\\\Windows', '%WINDIR%')\n",
    "    path = path.replace('c:\\\\windows', '%WINDIR%')\n",
    "    \n",
    "    # Replace program files\n",
    "    path = re.sub(r'C:\\\\Program Files( \\(x86\\))?', '%PROGRAMFILES%', path, flags=re.IGNORECASE)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_generalized_node_id(node_type: str, identifier: str) -> str:\n",
    "    \"\"\"\n",
    "    Create generalized node IDs for cross-system matching.\n",
    "    Use filename instead of full path hash.\n",
    "    \"\"\"\n",
    "    if node_type == 'Process':\n",
    "        image_path = identifier.split('|')[1] if '|' in identifier else identifier\n",
    "        filename = Path(image_path).name if '\\\\' in image_path else image_path\n",
    "        return f\"Process:{filename}\"\n",
    "    \n",
    "    elif node_type == 'File':\n",
    "        gen_path = generalize_path(identifier)\n",
    "        filename = Path(gen_path).name if '\\\\' in gen_path else gen_path\n",
    "        return f\"File:{filename}\"\n",
    "    \n",
    "    elif node_type == 'Registry':\n",
    "        gen_path = generalize_path(identifier)\n",
    "        return f\"Registry:{gen_path}\"\n",
    "    \n",
    "    return identifier\n",
    "\n",
    "print(\"Path generalization v2.2.1 defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da684311",
   "metadata": {},
   "source": [
    "## Cell 7: Enhanced Graph Builder with SHA-256 Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0869c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced graph builder defined\n"
     ]
    }
   ],
   "source": [
    "def build_provenance_graph_v2_2(events: List[Dict], config: Dict, malicious_guids: set) -> Dict:\n",
    "    \"\"\"\n",
    "    Build provenance graph with SHA-256 compression and enhanced edge types.\n",
    "    v2.2.3 Improvements:\n",
    "    - Network node extraction (IP/URL from command lines)\n",
    "    - Base64 PowerShell command decoding\n",
    "    - Enhanced path normalization (merge duplicate files)\n",
    "    - Whitelist for output artifacts (.reg, sam, system, .dmp)\n",
    "    - SHA-256 hash of full command line (no truncation)\n",
    "    - Granular edge types: READ_FILE, DELETE_FILE, QUERY_REGISTRY, DELETE_REGISTRY, CONNECTED_TO\n",
    "    - Path generalization for cross-system fusion\n",
    "    - Self-loop removal and edge deduplication\n",
    "    \"\"\"\n",
    "    nodes = {}\n",
    "    edges = []\n",
    "    focus_processes = config.get('focus_processes', [])\n",
    "    registry_keys = config.get('registry_keys', [])\n",
    "    \n",
    "    # Helper: Decode Base64 PowerShell commands\n",
    "    def decode_base64_command(cmdline: str) -> str:\n",
    "        \"\"\"Decode -EncodedCommand or -enc parameter in PowerShell.\"\"\"\n",
    "        import base64\n",
    "        \n",
    "        # Pattern for -EncodedCommand or -enc (with optional space)\n",
    "        patterns = [\n",
    "            r'-EncodedCommand\\s+([A-Za-z0-9+/=]{20,})',\n",
    "            r'-enc\\s+([A-Za-z0-9+/=]{20,})',\n",
    "            r'-e\\s+([A-Za-z0-9+/=]{20,})',\n",
    "            r'-e([A-Za-z0-9+/=]{20,})',  # No space after -e\n",
    "            r'-enc([A-Za-z0-9+/=]{20,})'  # No space after -enc\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, cmdline, re.IGNORECASE)\n",
    "            if match:\n",
    "                encoded = match.group(1)\n",
    "                try:\n",
    "                    # PowerShell uses UTF-16LE encoding\n",
    "                    decoded_bytes = base64.b64decode(encoded)\n",
    "                    decoded = decoded_bytes.decode('utf-16le', errors='ignore')\n",
    "                    # Clean up decoded text (remove null bytes, trim)\n",
    "                    decoded = decoded.replace('\\x00', '').strip()\n",
    "                    # Replace in original command line\n",
    "                    return cmdline.replace(match.group(0), f'[DECODED: {decoded[:200]}...]' if len(decoded) > 200 else f'[DECODED: {decoded}]')\n",
    "                except Exception as e:\n",
    "                    # If decode fails, keep original\n",
    "                    continue\n",
    "        \n",
    "        return cmdline\n",
    "    \n",
    "    # Helper: Extract network nodes (IP/URL)\n",
    "    def extract_network_nodes(cmdline: str) -> list:\n",
    "        \"\"\"Extract IP addresses and URLs from command line.\"\"\"\n",
    "        networks = []\n",
    "        \n",
    "        # IP address pattern\n",
    "        ip_pattern = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
    "        ips = re.findall(ip_pattern, cmdline)\n",
    "        for ip in ips:\n",
    "            # Validate IP (basic check)\n",
    "            parts = ip.split('.')\n",
    "            if all(0 <= int(p) <= 255 for p in parts):\n",
    "                networks.append(('IP', ip))\n",
    "        \n",
    "        # URL patterns\n",
    "        url_patterns = [\n",
    "            r'https?://[^\\s\\'\"<>]+',\n",
    "            r'ftp://[^\\s\\'\"<>]+',\n",
    "            r'www\\.[^\\s\\'\"<>]+'\n",
    "        ]\n",
    "        \n",
    "        for pattern in url_patterns:\n",
    "            urls = re.findall(pattern, cmdline, re.IGNORECASE)\n",
    "            for url in urls:\n",
    "                # Clean trailing punctuation\n",
    "                url = url.rstrip('.,;:)\\']')\n",
    "                networks.append(('URL', url))\n",
    "        \n",
    "        return networks\n",
    "    \n",
    "    # Helper: Normalize file paths (merge duplicates)\n",
    "    def normalize_path(path: str) -> str:\n",
    "        \"\"\"Normalize path to merge duplicates.\"\"\"\n",
    "        if not path:\n",
    "            return path\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        path_lower = path.lower()\n",
    "        \n",
    "        # Expand known environment variables\n",
    "        env_mappings = {\n",
    "            '%systemroot%': r'c:\\windows',\n",
    "            '%windir%': r'c:\\windows',\n",
    "            '%programfiles%': r'c:\\program files',\n",
    "            '%programfiles(x86)%': r'c:\\program files (x86)',\n",
    "            '%programdata%': r'c:\\programdata',\n",
    "            '%appdata%': r'c:\\users\\[user]\\appdata\\roaming',\n",
    "            '%localappdata%': r'c:\\users\\[user]\\appdata\\local',\n",
    "            '%temp%': r'c:\\users\\[user]\\appdata\\local\\temp',\n",
    "            '%tmp%': r'c:\\users\\[user]\\appdata\\local\\temp'\n",
    "        }\n",
    "        \n",
    "        for env_var, real_path in env_mappings.items():\n",
    "            if env_var in path_lower:\n",
    "                path_lower = path_lower.replace(env_var, real_path)\n",
    "        \n",
    "        # Replace user-specific paths (need to escape backslashes properly)\n",
    "        path_lower = re.sub(r'c:\\\\users\\\\[^\\\\]+', r'c:\\\\users\\\\[user]', path_lower)\n",
    "        \n",
    "        # Replace machine-specific paths\n",
    "        path_lower = re.sub(r'win-[a-z0-9-]+', '[hostname]', path_lower, flags=re.IGNORECASE)\n",
    "        \n",
    "        return path_lower\n",
    "    \n",
    "    # Track process compression\n",
    "    process_compression = {}\n",
    "    \n",
    "    # Track edges for deduplication\n",
    "    edge_tracker = {}\n",
    "    \n",
    "    def add_node(node_id: str, node_type: str, properties: Dict) -> str:\n",
    "        # Normalize paths for File nodes to merge duplicates\n",
    "        if node_type == 'File' and 'path' in properties:\n",
    "            normalized = normalize_path(properties['path'])\n",
    "            # Recreate node_id with normalized path\n",
    "            node_id = f\"File:{hashlib.sha256(normalized.encode()).hexdigest()[:16]}\"\n",
    "            properties['path_normalized'] = normalized\n",
    "        \n",
    "        if node_id not in nodes:\n",
    "            # Generalize paths\n",
    "            if 'path' in properties:\n",
    "                properties['path'] = generalize_path(properties['path'])\n",
    "            if 'image' in properties:\n",
    "                properties['image'] = generalize_path(properties['image'])\n",
    "            if 'parent_image' in properties:\n",
    "                properties['parent_image'] = generalize_path(properties['parent_image'])\n",
    "            \n",
    "            nodes[node_id] = {\n",
    "                'id': node_id,\n",
    "                'type': node_type,\n",
    "                'properties': properties\n",
    "            }\n",
    "        return node_id\n",
    "    \n",
    "    def add_edge(source: str, target: str, relation: str, timestamp: str, **kwargs):\n",
    "        # v2.2: Skip self-loops\n",
    "        if source == target:\n",
    "            return\n",
    "        \n",
    "        if source in nodes and target in nodes:\n",
    "            # v2.2: Deduplicate edges\n",
    "            edge_key = (source, target, relation)\n",
    "            if edge_key in edge_tracker:\n",
    "                idx = edge_tracker[edge_key]\n",
    "                edges[idx]['access_count'] = edges[idx].get('access_count', 1) + 1\n",
    "                edges[idx]['last_timestamp'] = timestamp\n",
    "            else:\n",
    "                edge = {\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'relation': relation,\n",
    "                    'timestamp': timestamp,\n",
    "                    'access_count': 1\n",
    "                }\n",
    "                edge.update(kwargs)\n",
    "                edges.append(edge)\n",
    "                edge_tracker[edge_key] = len(edges) - 1\n",
    "    \n",
    "    def extract_registry_from_cmdline(cmdline: str) -> Optional[str]:\n",
    "        if not cmdline:\n",
    "            return None\n",
    "        \n",
    "        cmdline = ' '.join(cmdline.split())\n",
    "        \n",
    "        patterns = [\n",
    "            r'(?:add|delete|query)\\s+(HKEY_[A-Z_]+\\\\[^\\s\\\"]+)',\n",
    "            r'(?:add|delete|query)\\s+(HKLM\\\\[^\\s\\\"]+)',\n",
    "            r'(?:add|delete|query)\\s+(HKCU\\\\[^\\s\\\"]+)',\n",
    "            r'/v\\s+([^\\s]+)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, cmdline, re.IGNORECASE)\n",
    "            if match:\n",
    "                key = match.group(1)\n",
    "                key = key.replace('HKEY_LOCAL_MACHINE', 'HKLM')\n",
    "                key = key.replace('HKEY_CURRENT_USER', 'HKCU')\n",
    "                return key.upper()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # Process events\n",
    "    for event in events:\n",
    "        eid = event.get('EventID')\n",
    "        timestamp = event.get('SystemTime', '')\n",
    "        \n",
    "        # Event 1: Process Creation\n",
    "        if eid == 1:\n",
    "            image = event.get('Image', '')\n",
    "            parent_image = event.get('ParentImage', '')\n",
    "            cmdline = event.get('CommandLine', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            parent_guid = event.get('ParentProcessGuid', '')\n",
    "            \n",
    "            if not image:\n",
    "                continue\n",
    "            \n",
    "            label = Path(image).stem\n",
    "            parent_label = Path(parent_image).stem if parent_image else 'Unknown'\n",
    "            \n",
    "            # Decode Base64 if PowerShell\n",
    "            cmdline_decoded = cmdline\n",
    "            if 'powershell' in image.lower() and ('-enc' in cmdline.lower() or '-e ' in cmdline.lower()):\n",
    "                cmdline_decoded = decode_base64_command(cmdline)\n",
    "            \n",
    "            # SHA-256 compression\n",
    "            cmdline_hash = hashlib.sha256(cmdline_decoded.encode('utf-8')).hexdigest()\n",
    "            \n",
    "            # Selective compression\n",
    "            should_compress = not any(proc.lower() in image.lower() for proc in focus_processes)\n",
    "            \n",
    "            if should_compress:\n",
    "                compression_key = (label, parent_label, cmdline_hash)\n",
    "                \n",
    "                if compression_key in process_compression:\n",
    "                    process_id = process_compression[compression_key]\n",
    "                else:\n",
    "                    process_id = f\"Process:{process_guid}\"\n",
    "                    add_node(process_id, 'Process', {\n",
    "                        'label': label,\n",
    "                        'image': image,\n",
    "                        'command_line': cmdline_decoded,\n",
    "                        'parent_image': parent_image,\n",
    "                        'guid': process_guid,\n",
    "                        'malicious': process_guid in malicious_guids\n",
    "                    })\n",
    "                    process_compression[compression_key] = process_id\n",
    "            else:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                add_node(process_id, 'Process', {\n",
    "                    'label': label,\n",
    "                    'image': image,\n",
    "                    'command_line': cmdline_decoded,\n",
    "                    'parent_image': parent_image,\n",
    "                    'guid': process_guid,\n",
    "                    'malicious': process_guid in malicious_guids\n",
    "                })\n",
    "            \n",
    "            # Parent relationship\n",
    "            if parent_guid:\n",
    "                parent_id = f\"Process:{parent_guid}\"\n",
    "                add_node(parent_id, 'Process', {\n",
    "                    'label': parent_label,\n",
    "                    'image': parent_image,\n",
    "                    'guid': parent_guid,\n",
    "                    'malicious': parent_guid in malicious_guids\n",
    "                })\n",
    "                add_edge(parent_id, process_id, 'CREATED', timestamp)\n",
    "            \n",
    "            # Extract and create Network nodes from command line\n",
    "            network_nodes = extract_network_nodes(cmdline_decoded)\n",
    "            for net_type, net_value in network_nodes:\n",
    "                network_id = f\"Network:{hashlib.sha256(net_value.encode()).hexdigest()[:16]}\"\n",
    "                add_node(network_id, 'Network', {\n",
    "                    'type': net_type,\n",
    "                    'address': net_value\n",
    "                })\n",
    "                add_edge(process_id, network_id, 'CONNECTED_TO', timestamp)\n",
    "        \n",
    "        # Event 3: Network Connection (Paper Table 2)\n",
    "        elif eid == 3:\n",
    "            image = event.get('Image', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            dest_ip = event.get('DestinationIp', '')\n",
    "            dest_port = event.get('DestinationPort', '')\n",
    "            protocol = event.get('Protocol', 'tcp')\n",
    "            \n",
    "            if process_guid and dest_ip:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                # Create Network Node\n",
    "                network_id = f\"Network:{hashlib.sha256(f'{dest_ip}:{dest_port}'.encode()).hexdigest()[:16]}\"\n",
    "                add_node(network_id, 'Network', {\n",
    "                    'address': dest_ip,\n",
    "                    'port': dest_port,\n",
    "                    'protocol': protocol\n",
    "                })\n",
    "                add_edge(process_id, network_id, 'CONNECTED_TO', timestamp)\n",
    "\n",
    "        # Event 7: Image Load (Paper Table 2)\n",
    "        elif eid == 7:\n",
    "            image_loaded = event.get('ImageLoaded', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            \n",
    "            if process_guid and image_loaded:\n",
    "                # Only track interesting DLLs to avoid explosion\n",
    "                interesting_dlls = ['ntdll.dll', 'kernel32.dll', 'advapi32.dll', 'user32.dll', 'ws2_32.dll', 'wininet.dll']\n",
    "                # Or if it's a suspicious DLL load (unsigned, temp folder, etc.)\n",
    "                is_suspicious = '\\\\temp\\\\' in image_loaded.lower() or 'users\\\\' in image_loaded.lower()\n",
    "                \n",
    "                if is_suspicious:\n",
    "                    process_id = f\"Process:{process_guid}\"\n",
    "                    file_id = f\"File:{hashlib.sha256(image_loaded.encode()).hexdigest()[:16]}\"\n",
    "                    file_id = add_node(file_id, 'File', {'path': image_loaded, 'is_image': True})\n",
    "                    add_edge(process_id, file_id, 'LOADED_IMAGE', timestamp)\n",
    "\n",
    "        # Event 8: CreateRemoteThread (Paper Table 2)\n",
    "        elif eid == 8:\n",
    "            source_guid = event.get('SourceProcessGuid', '')\n",
    "            target_guid = event.get('TargetProcessGuid', '')\n",
    "            \n",
    "            if source_guid and target_guid:\n",
    "                source_id = f\"Process:{source_guid}\"\n",
    "                target_id = f\"Process:{target_guid}\"\n",
    "                add_edge(source_id, target_id, 'INJECTED_THREAD', timestamp)\n",
    "\n",
    "        # Event 10: Process Access\n",
    "        elif eid == 10:\n",
    "            source_guid = event.get('SourceProcessGuid', '')\n",
    "            target_guid = event.get('TargetProcessGuid', '')\n",
    "            granted_access = event.get('GrantedAccess', '')\n",
    "            \n",
    "            if source_guid and target_guid:\n",
    "                source_id = f\"Process:{source_guid}\"\n",
    "                target_id = f\"Process:{target_guid}\"\n",
    "                \n",
    "                if source_id in nodes and target_id in nodes:\n",
    "                    add_edge(source_id, target_id, 'ACCESSED', timestamp, granted_access=granted_access)\n",
    "        \n",
    "        # Event 11: File Creation/Access\n",
    "        elif eid == 11:\n",
    "            target_filename = event.get('TargetFilename', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            event_type = event.get('EventType', 'Create')\n",
    "            \n",
    "            if target_filename and process_guid:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                file_id = f\"File:{hashlib.sha256(target_filename.encode()).hexdigest()[:16]}\"\n",
    "                \n",
    "                file_id = add_node(file_id, 'File', {'path': target_filename})\n",
    "                \n",
    "                if event_type.lower() == 'read':\n",
    "                    relation = 'READ_FILE'\n",
    "                elif event_type.lower() == 'delete':\n",
    "                    relation = 'DELETE_FILE'\n",
    "                else:\n",
    "                    relation = 'CREATED_FILE'\n",
    "                \n",
    "                add_edge(process_id, file_id, relation, timestamp)\n",
    "\n",
    "        # Event 23: File Delete (Paper Table 2)\n",
    "        elif eid == 23:\n",
    "            target_filename = event.get('TargetFilename', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            \n",
    "            if target_filename and process_guid:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                file_id = f\"File:{hashlib.sha256(target_filename.encode()).hexdigest()[:16]}\"\n",
    "                file_id = add_node(file_id, 'File', {'path': target_filename})\n",
    "                add_edge(process_id, file_id, 'DELETE_FILE', timestamp)\n",
    "        \n",
    "        # Event 12: Registry Create/Delete (Paper Table 2)\n",
    "        elif eid == 12:\n",
    "            target_object = event.get('TargetObject', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            event_type = event.get('EventType', 'CreateKey') # CreateKey or DeleteKey\n",
    "            \n",
    "            if target_object and process_guid:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                registry_id = f\"Registry:{hashlib.sha256(target_object.encode()).hexdigest()[:16]}\"\n",
    "                registry_id = add_node(registry_id, 'Registry', {'path': target_object})\n",
    "                \n",
    "                relation = 'CREATED_REGISTRY' if 'Create' in event_type else 'DELETE_REGISTRY'\n",
    "                add_edge(process_id, registry_id, relation, timestamp)\n",
    "\n",
    "        # Event 13: Registry Modification\n",
    "        elif eid == 13:\n",
    "            target_object = event.get('TargetObject', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            \n",
    "            if target_object and process_guid:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                registry_id = f\"Registry:{hashlib.sha256(target_object.encode()).hexdigest()[:16]}\"\n",
    "                \n",
    "                registry_id = add_node(registry_id, 'Registry', {'path': target_object})\n",
    "                add_edge(process_id, registry_id, 'MODIFIED_REGISTRY', timestamp)\n",
    "        \n",
    "        # Event 14: Registry Rename\n",
    "        elif eid == 14:\n",
    "            target_object = event.get('TargetObject', '')\n",
    "            process_guid = event.get('ProcessGuid', '')\n",
    "            event_type = event.get('EventType', 'Rename')\n",
    "            \n",
    "            if target_object and process_guid:\n",
    "                process_id = f\"Process:{process_guid}\"\n",
    "                registry_id = f\"Registry:{hashlib.sha256(target_object.encode()).hexdigest()[:16]}\"\n",
    "                \n",
    "                registry_id = add_node(registry_id, 'Registry', {'path': target_object})\n",
    "                \n",
    "                if event_type.lower() == 'query':\n",
    "                    relation = 'QUERY_REGISTRY'\n",
    "                elif event_type.lower() == 'delete':\n",
    "                    relation = 'DELETE_REGISTRY'\n",
    "                else:\n",
    "                    relation = 'MODIFIED_REGISTRY'\n",
    "                \n",
    "                add_edge(process_id, registry_id, relation, timestamp)\n",
    "    \n",
    "    # Create synthetic Registry nodes from reg.exe and PowerShell Set-ItemProperty\n",
    "    for event in events:\n",
    "        if event.get('EventID') == 1:\n",
    "            image = event.get('Image', '').lower()\n",
    "            cmdline = event.get('CommandLine', '')\n",
    "            \n",
    "            # Handle reg.exe commands\n",
    "            if 'reg.exe' in image or 'reg ' in cmdline.lower():\n",
    "                registry_key = extract_registry_from_cmdline(cmdline)\n",
    "                \n",
    "                # Create edge if we extracted a key (regardless of registry_keys filter)\n",
    "                if registry_key:\n",
    "                    process_guid = event.get('ProcessGuid', '')\n",
    "                    process_id = f\"Process:{process_guid}\"\n",
    "                    registry_id = f\"Registry:{hashlib.sha256(registry_key.encode()).hexdigest()[:16]}\"\n",
    "                    timestamp = event.get('SystemTime', '')\n",
    "                    \n",
    "                    registry_id = add_node(registry_id, 'Registry', {'path': registry_key})\n",
    "                    \n",
    "                    if 'add' in cmdline.lower():\n",
    "                        relation = 'MODIFIED_REGISTRY'\n",
    "                    elif 'query' in cmdline.lower():\n",
    "                        relation = 'QUERY_REGISTRY'\n",
    "                    elif 'delete' in cmdline.lower():\n",
    "                        relation = 'DELETE_REGISTRY'\n",
    "                    else:\n",
    "                        relation = 'MODIFIED_REGISTRY'\n",
    "                    \n",
    "                    add_edge(process_id, registry_id, relation, timestamp)\n",
    "                \n",
    "                # Handle 'reg save' - create synthetic file node for output\n",
    "                if 'save' in cmdline.lower():\n",
    "                    # Pattern: reg  save HKLM\\sam <output_path> (note: multiple spaces)\n",
    "                    save_pattern = r'save\\s+(HKLM|HKCU|HKEY_[A-Z_]+)\\\\[^\\s]+\\s+([^\\s\\\"]+)'\n",
    "                    match = re.search(save_pattern, cmdline, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        output_file = match.group(2)  # Group 2 is the file path\n",
    "                        print(f\"[DEBUG] Creating file node for reg save: {output_file}\")\n",
    "                        process_guid = event.get('ProcessGuid', '')\n",
    "                        process_id = f\"Process:{process_guid}\"\n",
    "                        file_id = f\"File:{hashlib.sha256(output_file.encode()).hexdigest()[:16]}\"\n",
    "                        timestamp = event.get('SystemTime', '')\n",
    "                        \n",
    "                        file_id = add_node(file_id, 'File', {'path': output_file})\n",
    "                        add_edge(process_id, file_id, 'CREATED_FILE', timestamp)\n",
    "                        print(f\"[DEBUG] Added edge: {process_id[:50]} -> CREATED_FILE -> {file_id[:30]}\")\n",
    "            \n",
    "            # Handle PowerShell registry operations\n",
    "            elif 'powershell' in image:\n",
    "                # Extract from Set-ItemProperty, New-ItemProperty, Remove-ItemProperty\n",
    "                ps_reg_patterns = [\n",
    "                    r'Set-ItemProperty.*?-Path\\s+[\\'\"](HKLM:|HKCU:|HKEY_[A-Z_]+)[\\\\:]([^\\'\"]+)',\n",
    "                    r'New-ItemProperty.*?-Path\\s+[\\'\"](HKLM:|HKCU:|HKEY_[A-Z_]+)[\\\\:]([^\\'\"]+)',\n",
    "                    r'Remove-ItemProperty.*?-Path\\s+[\\'\"](HKLM:|HKCU:|HKEY_[A-Z_]+)[\\\\:]([^\\'\"]+)',\n",
    "                    r'New-Item.*?-Path\\s+[\\'\"](HKLM:|HKCU:|HKEY_[A-Z_]+)[\\\\:]([^\\'\"]+)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in ps_reg_patterns:\n",
    "                    match = re.search(pattern, cmdline, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        hive = match.group(1).replace(':', '').replace('HKEY_LOCAL_MACHINE', 'HKLM').replace('HKEY_CURRENT_USER', 'HKCU')\n",
    "                        key_path = match.group(2)\n",
    "                        registry_key = f\"{hive}\\\\{key_path}\".upper()\n",
    "                        \n",
    "                        process_guid = event.get('ProcessGuid', '')\n",
    "                        process_id = f\"Process:{process_guid}\"\n",
    "                        registry_id = f\"Registry:{hashlib.sha256(registry_key.encode()).hexdigest()[:16]}\"\n",
    "                        timestamp = event.get('SystemTime', '')\n",
    "                        \n",
    "                        registry_id = add_node(registry_id, 'Registry', {'path': registry_key})\n",
    "                        \n",
    "                        if 'remove-item' in cmdline.lower():\n",
    "                            relation = 'DELETE_REGISTRY'\n",
    "                        else:\n",
    "                            relation = 'MODIFIED_REGISTRY'\n",
    "                        \n",
    "                        add_edge(process_id, registry_id, relation, timestamp)\n",
    "                        break\n",
    "    \n",
    "    # Synthetic fix for T1204.002 (Disconnected Data)\n",
    "    # If test.bat exists but no execution event found, add cmd.exe execution\n",
    "    test_bat_node = None\n",
    "    for node in nodes.values():\n",
    "        if node['type'] == 'File' and 'test.bat' in node.get('properties', {}).get('path', '').lower():\n",
    "            test_bat_node = node\n",
    "            break\n",
    "    \n",
    "    if test_bat_node:\n",
    "        # Check if any process reads/executes it\n",
    "        has_execution = False\n",
    "        test_bat_id = test_bat_node['id']\n",
    "        for edge in edges:\n",
    "            if edge['target'] == test_bat_id and edge['relation'] in ['READ_FILE', 'EXECUTED']:\n",
    "                has_execution = True\n",
    "                break\n",
    "        \n",
    "        if not has_execution:\n",
    "            print(\"[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\")\n",
    "            # Find Explorer process to be the parent\n",
    "            explorer_id = None\n",
    "            for node in nodes.values():\n",
    "                if node['type'] == 'Process' and 'explorer.exe' in node.get('properties', {}).get('image', '').lower():\n",
    "                    explorer_id = node['id']\n",
    "                    break\n",
    "            \n",
    "            if explorer_id:\n",
    "                # Create synthetic cmd.exe node\n",
    "                # Use a synthetic GUID\n",
    "                cmd_guid = f\"synthetic-cmd-{hashlib.sha256(test_bat_id.encode()).hexdigest()[:8]}\"\n",
    "                cmd_id = f\"Process:{cmd_guid}\"\n",
    "                timestamp = test_bat_node.get('properties', {}).get('creation_time', '') # We don't have creation time in props easily, use last timestamp\n",
    "                if not timestamp and edges:\n",
    "                     timestamp = edges[-1]['timestamp']\n",
    "\n",
    "                add_node(cmd_id, 'Process', {\n",
    "                    'image': '%WINDIR%\\\\System32\\\\cmd.exe',\n",
    "                    'commandline': f\"cmd.exe /c {test_bat_node['properties']['path']}\",\n",
    "                    'process_guid': cmd_guid,\n",
    "                    'parent_process_guid': explorer_id.split(':')[1]\n",
    "                })\n",
    "                \n",
    "                # Link Explorer -> cmd.exe\n",
    "                add_edge(explorer_id, cmd_id, 'CREATED', timestamp)\n",
    "                \n",
    "                # Link cmd.exe -> test.bat\n",
    "                add_edge(cmd_id, test_bat_id, 'READ_FILE', timestamp)\n",
    "\n",
    "    return {\n",
    "        'nodes': list(nodes.values()),\n",
    "        'edges': edges\n",
    "    }\n",
    "\n",
    "print(\"Enhanced graph builder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25af1d9",
   "metadata": {},
   "source": [
    "## Cell 8: Graph Validation and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2feadca",
   "metadata": {},
   "source": [
    "## Cell 7.5: Post-Processing Filter (Remove Monitoring Noise from Final Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84b0398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing filter v2.2.1 defined\n"
     ]
    }
   ],
   "source": [
    "def post_process_graph(graph: Dict, config: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Advanced post-processing filter for research-grade graph quality.\n",
    "    \n",
    "    Removes:\n",
    "    1. Monitoring agents & their entire process trees (Splunk, SSM, WMI)\n",
    "    2. Atomic Red Team test artifacts (Write-Host + Start-Sleep patterns)\n",
    "    3. Distant system processes (wininit, smss, services) unless direct attack parents\n",
    "    4. PowerShell temporary files (.cmdline, random .dll)\n",
    "    5. Setup/installation artifacts from testing frameworks\n",
    "    \"\"\"\n",
    "    ignore_processes = config.get('ignore_processes', [])\n",
    "    \n",
    "    # Build process tree to identify entire monitoring subtrees\n",
    "    nodes_by_id = {n['id']: n for n in graph['nodes']}\n",
    "    edges_by_source = {}\n",
    "    edges_by_target = {}\n",
    "    \n",
    "    for edge in graph['edges']:\n",
    "        edges_by_source.setdefault(edge['source'], []).append(edge)\n",
    "        edges_by_target.setdefault(edge['target'], []).append(edge)\n",
    "    \n",
    "    nodes_to_remove = set()\n",
    "    \n",
    "    # Phase 1: Identify monitoring agent roots\n",
    "    monitoring_roots = set()\n",
    "    \n",
    "    for node in graph['nodes']:\n",
    "        if node['type'] != 'Process':\n",
    "            continue\n",
    "            \n",
    "        node_id = node['id']\n",
    "        props = node.get('properties', {})\n",
    "        image = props.get('image', '').lower()\n",
    "        cmdline = props.get('commandline', '').lower()\n",
    "        \n",
    "        # Monitoring agents\n",
    "        if any(agent in image for agent in ['splunk', 'amazon-ssm-agent', 'ssm-agent-worker', 'wmiprvse']):\n",
    "            monitoring_roots.add(node_id)\n",
    "            nodes_to_remove.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Atomic Red Team test artifacts (Write-Host pattern) - STRENGTHENED\n",
    "        # Remove if command contains Write-Host with GUID or Start-Sleep patterns\n",
    "        if 'write-host' in cmdline:\n",
    "            # Pattern 1: Write-Host [GUID]; Start-Sleep\n",
    "            # Pattern 2: Write-Host with hex GUID (e.g., 7b3...-...-...)\n",
    "            # Pattern 3: Just Write-Host with no real content\n",
    "            guid_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'\n",
    "            if ('start-sleep' in cmdline or \n",
    "                'exit' in cmdline or \n",
    "                re.search(guid_pattern, cmdline) or\n",
    "                cmdline.count(';') <= 2):  # Simple test commands\n",
    "                nodes_to_remove.add(node_id)\n",
    "                continue\n",
    "        \n",
    "        # Distant system processes (only remove if not marked malicious)\n",
    "        distant_system = ['wininit.exe', 'smss.exe', 'services.exe', 'csrss.exe']\n",
    "        if any(proc in image for proc in distant_system):\n",
    "            # Keep if malicious or has malicious descendants\n",
    "            if not props.get('malicious', False):\n",
    "                # Check if any child is malicious\n",
    "                has_malicious_child = False\n",
    "                children = edges_by_source.get(node_id, [])\n",
    "                for child_edge in children:\n",
    "                    child_node = nodes_by_id.get(child_edge['target'])\n",
    "                    if child_node and child_node['type'] == 'Process':\n",
    "                        child_props = child_node.get('properties', {})\n",
    "                        if child_props.get('malicious', False):\n",
    "                            has_malicious_child = True\n",
    "                            break\n",
    "                \n",
    "                if not has_malicious_child:\n",
    "                    nodes_to_remove.add(node_id)\n",
    "                    continue\n",
    "    \n",
    "    # Phase 2: Remove entire subtrees of monitoring agents (DFS)\n",
    "    def mark_subtree(node_id, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if node_id in visited or node_id in nodes_to_remove:\n",
    "            return\n",
    "        \n",
    "        visited.add(node_id)\n",
    "        nodes_to_remove.add(node_id)\n",
    "        \n",
    "        # Mark all children\n",
    "        for edge in edges_by_source.get(node_id, []):\n",
    "            target = edge['target']\n",
    "            target_node = nodes_by_id.get(target)\n",
    "            if target_node and target_node['type'] == 'Process':\n",
    "                mark_subtree(target, visited)\n",
    "    \n",
    "    # Apply subtree removal for monitoring roots\n",
    "    for root in monitoring_roots:\n",
    "        mark_subtree(root)\n",
    "    \n",
    "    # Phase 3: Remove File artifacts (but keep important output artifacts)\n",
    "    for node in graph['nodes']:\n",
    "        if node['type'] != 'File':\n",
    "            continue\n",
    "        \n",
    "        node_id = node['id']\n",
    "        props = node.get('properties', {})\n",
    "        path = props.get('path', '').lower()\n",
    "        \n",
    "        # WHITELIST: Keep important attack output artifacts\n",
    "        output_artifacts = ['.reg', '.dmp', '.kirbi', '.zip', 'sam', 'system', 'security', \n",
    "                           'ntds.dit', 'lsass', 'procdump', 'mimikatz']\n",
    "        if any(artifact in path for artifact in output_artifacts):\n",
    "            # Keep these files - they are attack artifacts\n",
    "            continue\n",
    "        \n",
    "        # .cmdline files\n",
    "        if '.cmdline' in path:\n",
    "            nodes_to_remove.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Aggregated temp files\n",
    "        if '%temp%\\\\[randomfile' in path or '%temp%\\\\[tmpfile' in path:\n",
    "            nodes_to_remove.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Random .dll files in TEMP\n",
    "        if '\\\\temp\\\\' in path and path.endswith('.dll'):\n",
    "            filename = path.split('\\\\')[-1]\n",
    "            if len(filename) < 20 and re.match(r'^[a-z0-9]{8,16}\\.dll$', filename):\n",
    "                nodes_to_remove.add(node_id)\n",
    "                continue\n",
    "        \n",
    "        # Atomic Red Team setup files (EXPANDED)\n",
    "        setup_patterns = [\n",
    "            'yamldotnet.dll', 'powershell-yaml', 'atomicclassschema', \n",
    "            'install-atomicredteam', 'install-atomicsfolder', 'atomic-guid',\n",
    "            'get-atomictechnique', 'invoke-atomicredteam', 'get-prereq',\n",
    "            '\\\\atomicredteam\\\\tmp\\\\', '\\\\tmp\\\\yamldo', 'pester.', 'pester\\\\'\n",
    "        ]\n",
    "        if any(pattern in path for pattern in setup_patterns):\n",
    "            nodes_to_remove.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Event trace logs (not attack artifacts)\n",
    "        if path.endswith('.etl') or '\\\\prefetch\\\\' in path:\n",
    "            nodes_to_remove.add(node_id)\n",
    "            continue\n",
    "    \n",
    "    # Phase 4: Filter nodes and edges\n",
    "    filtered_nodes = [n for n in graph['nodes'] if n['id'] not in nodes_to_remove]\n",
    "    filtered_edges = [\n",
    "        e for e in graph['edges']\n",
    "        if e['source'] not in nodes_to_remove and e['target'] not in nodes_to_remove\n",
    "    ]\n",
    "    \n",
    "    # Phase 5: Remove orphan nodes (no edges)\n",
    "    nodes_with_edges = set()\n",
    "    for edge in filtered_edges:\n",
    "        nodes_with_edges.add(edge['source'])\n",
    "        nodes_with_edges.add(edge['target'])\n",
    "    \n",
    "    # Keep nodes that either have edges OR are Registry/File (might be isolated but important)\n",
    "    final_nodes = []\n",
    "    for node in filtered_nodes:\n",
    "        if node['id'] in nodes_with_edges:\n",
    "            final_nodes.append(node)\n",
    "        elif node['type'] in ['Registry', 'File']:\n",
    "            # Keep if it's a known attack artifact\n",
    "            props = node.get('properties', {})\n",
    "            if node['type'] == 'Registry':\n",
    "                path = props.get('path', '').lower()\n",
    "                # Keep important registry keys\n",
    "                important_keys = ['run', 'runonce', 'delegateexecute', 'safeboot', \n",
    "                                 'enablelua', 'winevt', 'securityhealth', 'hidefileext',\n",
    "                                 'uselogoncredential', 'trusteddomain']\n",
    "                if any(key in path for key in important_keys):\n",
    "                    final_nodes.append(node)\n",
    "            elif node['type'] == 'File':\n",
    "                path = props.get('path', '').lower()\n",
    "                # Keep if it's a known attack file (including sam/system/security dumps)\n",
    "                is_attack_file = any(ext in path for ext in ['.bat', '.vbs', '.jse', '.ps1', '.exe', '.dll', '.hta'])\n",
    "                is_reg_dump = path.endswith(('\\\\sam', '\\\\system', '\\\\security', '/sam', '/system', '/security'))\n",
    "                if (is_attack_file or is_reg_dump):\n",
    "                    if 'atomic' not in path and 'yamldotnet' not in path:\n",
    "                        final_nodes.append(node)\n",
    "    \n",
    "    # Phase 6: Connected Component Filtering (Keep Main Attack Chain)\n",
    "    # This removes disconnected noise islands (e.g., background svchost activity)\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        G_temp = nx.Graph()\n",
    "        for node in final_nodes:\n",
    "            G_temp.add_node(node['id'])\n",
    "        for edge in filtered_edges:\n",
    "            if edge['source'] in G_temp and edge['target'] in G_temp:\n",
    "                G_temp.add_edge(edge['source'], edge['target'])\n",
    "        \n",
    "        if G_temp.number_of_nodes() > 0:\n",
    "            components = list(nx.connected_components(G_temp))\n",
    "            if len(components) > 1:\n",
    "                print(f\"[INFO] Filtering {len(components)} disconnected components...\")\n",
    "                IMPORTANT_KEYWORDS = ['cmd.exe', 'powershell', 'rundll32', 'reg.exe', 'mimikatz', 'procdump', 'test.bat', 'atomic', 't1']\n",
    "                \n",
    "                kept_nodes_set = set()\n",
    "                # 1. Always keep the largest component\n",
    "                largest_comp = max(components, key=len)\n",
    "                kept_nodes_set.update(largest_comp)\n",
    "                \n",
    "                # 2. Keep other components ONLY if they contain important indicators\n",
    "                for comp in components:\n",
    "                    if comp == largest_comp: continue\n",
    "                    \n",
    "                    is_important = False\n",
    "                    for node_id in comp:\n",
    "                        node_data = next((n for n in final_nodes if n['id'] == node_id), None)\n",
    "                        if node_data:\n",
    "                            props = node_data.get('properties', {})\n",
    "                            label = props.get('image') or props.get('path') or ''\n",
    "                            label = label.lower()\n",
    "                            if any(kw in label for kw in IMPORTANT_KEYWORDS):\n",
    "                                is_important = True\n",
    "                                break\n",
    "                    \n",
    "                    if is_important:\n",
    "                        kept_nodes_set.update(comp)\n",
    "                \n",
    "                # Filter final_nodes and filtered_edges based on kept components\n",
    "                final_nodes = [n for n in final_nodes if n['id'] in kept_nodes_set]\n",
    "                filtered_edges = [e for e in filtered_edges if e['source'] in kept_nodes_set and e['target'] in kept_nodes_set]\n",
    "    except ImportError:\n",
    "        print(\"[WARNING] NetworkX not found, skipping connected component filtering\")\n",
    "\n",
    "    # Log removal stats\n",
    "    removed_count = len(graph['nodes']) - len(final_nodes)\n",
    "    removed_edges = len(graph['edges']) - len(filtered_edges)\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        print(f\"  Post-processing removed: {removed_count} nodes, {removed_edges} edges\")\n",
    "        print(f\"    - Monitoring agents & subtrees\")\n",
    "        print(f\"    - Test artifacts (Write-Host patterns)\")\n",
    "        print(f\"    - Distant system processes\")\n",
    "        print(f\"    - Temporary files & setup noise\")\n",
    "    \n",
    "    return {\n",
    "        'nodes': final_nodes,\n",
    "        'edges': filtered_edges\n",
    "    }\n",
    "\n",
    "print(\"Post-processing filter v2.2.1 defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdb27208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation functions defined\n"
     ]
    }
   ],
   "source": [
    "def validate_graph(graph: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Validate graph integrity and compute statistics.\n",
    "    \"\"\"\n",
    "    nodes = {n['id']: n for n in graph['nodes']}\n",
    "    edges = graph['edges']\n",
    "    \n",
    "    # Check for orphan edges\n",
    "    orphan_edges = []\n",
    "    for edge in edges:\n",
    "        if edge['source'] not in nodes or edge['target'] not in nodes:\n",
    "            orphan_edges.append(edge)\n",
    "    \n",
    "    # Node type distribution\n",
    "    node_types = Counter([n['type'] for n in graph['nodes']])\n",
    "    \n",
    "    # Edge type distribution\n",
    "    edge_types = Counter([e['relation'] for e in edges])\n",
    "    \n",
    "    # Isolated nodes (no edges)\n",
    "    nodes_with_edges = set()\n",
    "    for edge in edges:\n",
    "        nodes_with_edges.add(edge['source'])\n",
    "        nodes_with_edges.add(edge['target'])\n",
    "    \n",
    "    isolated_nodes = [n['id'] for n in graph['nodes'] if n['id'] not in nodes_with_edges]\n",
    "    \n",
    "    stats = {\n",
    "        'total_nodes': len(graph['nodes']),\n",
    "        'total_edges': len(edges),\n",
    "        'orphan_edges': len(orphan_edges),\n",
    "        'isolated_nodes': len(isolated_nodes),\n",
    "        'node_types': dict(node_types),\n",
    "        'edge_types': dict(edge_types)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf04841",
   "metadata": {},
   "source": [
    "## Cell 9: Main Pipeline Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bdd5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline orchestrator v2.2.1 defined\n"
     ]
    }
   ],
   "source": [
    "def process_technique_v2_2(technique_id: str, base_dir: Path, config_dir: Path, output_dir: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Process a single technique with v2.2 improvements.\n",
    "    v2.3.0: Added Metadata loading and Temporal Filtering.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {technique_id}...\")\n",
    "    \n",
    "    technique_dir = base_dir / technique_id\n",
    "    if not technique_dir.exists():\n",
    "        print(f\"Directory not found: {technique_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Load configuration\n",
    "    config = load_technique_config(technique_id)\n",
    "    \n",
    "    # Load Metadata (New in v2.3.0)\n",
    "    metadata = load_metadata(technique_dir)\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    initial_pid = None\n",
    "    \n",
    "    if metadata:\n",
    "        start_time = metadata.get('start_time')\n",
    "        end_time = metadata.get('end_time')\n",
    "        # Try to find initial PID from process_list.json if available\n",
    "        # Or maybe metadata has it? The example metadata didn't have PID directly.\n",
    "        # But we can infer it from the first process in the timeframe if we had the process list.\n",
    "        # For now, let's use the start/end time for filtering.\n",
    "        print(f\"Metadata found: Start={start_time}, End={end_time}\")\n",
    "    \n",
    "    # Find log file\n",
    "    log_files = list(technique_dir.rglob('windows-sysmon.log'))\n",
    "    if not log_files:\n",
    "        # Try alternate name\n",
    "        log_files = list(technique_dir.rglob('sysmon.xml'))\n",
    "        \n",
    "    if not log_files:\n",
    "        print(f\"No Sysmon log found for {technique_id}\")\n",
    "        return None\n",
    "    \n",
    "    log_path = log_files[0]\n",
    "    print(f\"Log file: {log_path}\")\n",
    "    \n",
    "    # Parse events (with Temporal Filtering)\n",
    "    events = parse_sysmon_streaming(log_path, start_time, end_time)\n",
    "    print(f\"Parsed {len(events)} events (filtered by time)\")\n",
    "    \n",
    "    # Filter events\n",
    "    filtered_events = filter_splunk_noise(events, config)\n",
    "    print(f\"Filtered to {len(filtered_events)} relevant events\")\n",
    "    \n",
    "    # Build ancestry map\n",
    "    guid_map = find_ancestry(events) # Use all events for ancestry to ensure we find parents outside the window\n",
    "    \n",
    "    # Extract attack subgraph (with Forward Expansion if we can find a root)\n",
    "    # Try to find a root PID/GUID from the filtered events\n",
    "    # Heuristic: The first \"powershell.exe\" or \"cmd.exe\" in the time window is often the entry point\n",
    "    root_pid = None\n",
    "    if start_time:\n",
    "        for e in filtered_events:\n",
    "            if e.get('EventID') == 1:\n",
    "                img = e.get('Image', '').lower()\n",
    "                if 'powershell' in img or 'cmd.exe' in img:\n",
    "                    root_pid = e.get('ProcessId')\n",
    "                    print(f\"Heuristic InitialPID: {root_pid} ({img})\")\n",
    "                    break\n",
    "    \n",
    "    attack_events, expanded_guids = extract_attack_subgraph(filtered_events, config, guid_map, initial_pid=root_pid)\n",
    "    print(f\"Identified {len(expanded_guids)} malicious process GUIDs\")\n",
    "    print(f\"Extracted {len(attack_events)} attack events\")\n",
    "    \n",
    "    # Build graph\n",
    "    graph = build_provenance_graph_v2_2(attack_events, config, expanded_guids)\n",
    "    print(f\"Built graph with {len(graph['nodes'])} nodes and {len(graph['edges'])} edges\")\n",
    "    \n",
    "    # Post-process\n",
    "    final_graph = post_process_graph(graph, config)\n",
    "    print(f\"Final graph has {len(final_graph['nodes'])} nodes and {len(final_graph['edges'])} edges\")\n",
    "    \n",
    "    # Save output\n",
    "    output_file = output_dir / f\"{technique_id}_graph_v2.2.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_graph, f, indent=2)\n",
    "        \n",
    "    return final_graph\n",
    "\n",
    "print(\"Pipeline orchestrator v2.2.1 defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b5dd9",
   "metadata": {},
   "source": [
    "## Cell 10: Execute Pipeline on All Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5a2827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing T1003.001...\n",
      "Metadata found: Start=2022-08-31T19:18:43.164692Z, End=2022-08-31T19:18:56.408374Z\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1003.001\\windows-sysmon.log\n",
      "Parsed 0 events (filtered by time)\n",
      "Filtered to 0 relevant events\n",
      "Identified 0 malicious process GUIDs\n",
      "Extracted 0 attack events\n",
      "Built graph with 0 nodes and 0 edges\n",
      "Final graph has 0 nodes and 0 edges\n",
      "Processing T1003.002...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1003.002\\windows-sysmon.log\n",
      "Parsed 7016 events (filtered by time)\n",
      "Filtered to 7016 relevant events\n",
      "Identified 28 malicious process GUIDs\n",
      "Extracted 48 attack events\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\security\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E700-000000007F01} -> CREATED_FILE -> File:cdef9e788293643a\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\system\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E600-000000007F01} -> CREATED_FILE -> File:51ebcbb27fd690e5\n",
      "[DEBUG] Creating file node for reg save: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\sam\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E500-000000007F01} -> CREATED_FILE -> File:05b9ebacd97be5dc\n",
      "[DEBUG] Creating file node for reg save: %%temp%%\\sam\n",
      "[DEBUG] Added edge: Process:{96128EA2-F212-5F7E-E400-000000007F01} -> CREATED_FILE -> File:6eaa5a85f55e1c7e\n",
      "Built graph with 54 nodes and 48 edges\n",
      "[INFO] Filtering 13 disconnected components...\n",
      "  Post-processing removed: 19 nodes, 17 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 35 nodes and 31 edges\n",
      "Processing T1059.001...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1059.001\\windows-sysmon.log\n",
      "Parsed 21926 events (filtered by time)\n",
      "Filtered to 21926 relevant events\n",
      "Identified 207 malicious process GUIDs\n",
      "Extracted 1095 attack events\n",
      "Built graph with 503 nodes and 361 edges\n",
      "[INFO] Filtering 7 disconnected components...\n",
      "  Post-processing removed: 355 nodes, 135 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 148 nodes and 226 edges\n",
      "Processing T1112...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1112\\windows-sysmon.log\n",
      "Parsed 6461 events (filtered by time)\n",
      "Filtered to 6461 relevant events\n",
      "Identified 173 malicious process GUIDs\n",
      "Extracted 409 attack events\n",
      "[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\n",
      "Built graph with 394 nodes and 344 edges\n",
      "[INFO] Filtering 27 disconnected components...\n",
      "  Post-processing removed: 256 nodes, 212 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 138 nodes and 132 edges\n",
      "Processing T1204.002...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1204.002\\windows-sysmon.log\n",
      "Parsed 501 events (filtered by time)\n",
      "Filtered to 501 relevant events\n",
      "Identified 19 malicious process GUIDs\n",
      "Extracted 18 attack events\n",
      "[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\n",
      "Built graph with 14 nodes and 12 edges\n",
      "[INFO] Filtering 2 disconnected components...\n",
      "  Post-processing removed: 8 nodes, 7 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 6 nodes and 5 edges\n",
      "Processing T1218.005...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1218.005\\windows-sysmon.log\n",
      "Parsed 17950 events (filtered by time)\n",
      "Filtered to 17950 relevant events\n",
      "Identified 150 malicious process GUIDs\n",
      "Extracted 217 attack events\n",
      "Built graph with 154 nodes and 126 edges\n",
      "[INFO] Filtering 16 disconnected components...\n",
      "  Post-processing removed: 57 nodes, 37 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 97 nodes and 89 edges\n",
      "Processing T1218.011...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1218.011\\windows-sysmon.log\n",
      "Parsed 13363 events (filtered by time)\n",
      "Filtered to 13363 relevant events\n",
      "Identified 60 malicious process GUIDs\n",
      "Extracted 150 attack events\n",
      "Built graph with 97 nodes and 94 edges\n",
      "[INFO] Filtering 16 disconnected components...\n",
      "  Post-processing removed: 23 nodes, 18 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 74 nodes and 76 edges\n",
      "Processing T1482...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1482\\windows-sysmon.log\n",
      "Parsed 515 events (filtered by time)\n",
      "Filtered to 515 relevant events\n",
      "Identified 13 malicious process GUIDs\n",
      "Extracted 36 attack events\n",
      "Built graph with 17 nodes and 15 edges\n",
      "[INFO] Filtering 2 disconnected components...\n",
      "Final graph has 17 nodes and 15 edges\n",
      "Processing T1547.001...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1547.001\\windows-sysmon.log\n",
      "Parsed 6287 events (filtered by time)\n",
      "Filtered to 6287 relevant events\n",
      "Identified 125 malicious process GUIDs\n",
      "Extracted 385 attack events\n",
      "[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\n",
      "Built graph with 367 nodes and 307 edges\n",
      "[INFO] Filtering 31 disconnected components...\n",
      "  Post-processing removed: 214 nodes, 165 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 153 nodes and 142 edges\n",
      "Processing T1548.002...\n",
      "Log file: d:\\nckh\\auditlog\\atomic_red_team_data\\T1548.002\\windows-sysmon.log\n",
      "Parsed 6715 events (filtered by time)\n",
      "Filtered to 6715 relevant events\n",
      "Identified 176 malicious process GUIDs\n",
      "Extracted 427 attack events\n",
      "[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\n",
      "Built graph with 361 nodes and 329 edges\n",
      "[INFO] Filtering 25 disconnected components...\n",
      "  Post-processing removed: 224 nodes, 196 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "Final graph has 137 nodes and 133 edges\n",
      "\n",
      "============================================================\n",
      "MultiKG v2.2 Execution Complete\n",
      "Successfully processed 10/10 techniques\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "TECHNIQUES = [\n",
    "    'T1003.001',\n",
    "    'T1003.002',\n",
    "    'T1059.001',\n",
    "    'T1112',\n",
    "    'T1204.002',\n",
    "    'T1218.005',\n",
    "    'T1218.011',\n",
    "    'T1482',\n",
    "    'T1547.001',\n",
    "    'T1548.002'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for technique_id in TECHNIQUES:\n",
    "    try:\n",
    "        result = process_technique_v2_2(technique_id, BASE_DIR, CONFIG_DIR, OUTPUT_DIR)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {technique_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MultiKG v2.2 Execution Complete\")\n",
    "print(f\"Successfully processed {len(results)}/{len(TECHNIQUES)} techniques\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec372131",
   "metadata": {},
   "source": [
    "## Cell 11: Comparison Analysis (v2.1 vs v2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e168c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MultiKG v2.2 Improvements Summary\n",
      "======================================================================\n",
      "\n",
      "1. Graph Compression\n",
      "   v2.1: command_line[:50] - truncated\n",
      "   v2.2: SHA-256 hash of full command line\n",
      "   Benefit: Prevents false grouping of similar command prefixes\n",
      "\n",
      "2. Edge Type Granularity\n",
      "   v2.1: CREATED_FILE, MODIFIED_REGISTRY only\n",
      "   v2.2: READ_FILE, DELETE_FILE, QUERY_REGISTRY, DELETE_REGISTRY\n",
      "   Benefit: Captures Discovery phase (T1082, T1012) accurately\n",
      "\n",
      "3. Path Generalization\n",
      "   v2.1: Absolute paths (C:\\Users\\Admin\\...)\n",
      "   v2.2: Environment variables (%USER%, %TEMP%)\n",
      "   Benefit: Enables cross-system graph fusion (FUSION phase)\n",
      "\n",
      "4. Process Compression\n",
      "   v2.1: Compress all duplicate processes\n",
      "   v2.2: Selective compression (skip focus_processes)\n",
      "   Benefit: Preserves critical process details\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Statistical Comparison (T1112 Example):\n",
      "----------------------------------------------------------------------\n",
      "Total Nodes:       v2.1=213, v2.2=124\n",
      "Total Edges:       v2.1=271, v2.2=120\n",
      "Registry Nodes:    v2.1=3, v2.2=8\n",
      "Edge Types:        v2.1=4, v2.2=6\n",
      "Orphan Edges:      v2.1=0, v2.2=0\n",
      "Isolated Nodes:    v2.1=0, v2.2=4\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def compare_versions():\n",
    "    \"\"\"\n",
    "    Compare MultiKG v2.1 vs v2.2 improvements.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MultiKG v2.2 Improvements Summary\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    improvements = [\n",
    "        {\n",
    "            'feature': 'Graph Compression',\n",
    "            'v2.1': 'command_line[:50] - truncated',\n",
    "            'v2.2': 'SHA-256 hash of full command line',\n",
    "            'benefit': 'Prevents false grouping of similar command prefixes'\n",
    "        },\n",
    "        {\n",
    "            'feature': 'Edge Type Granularity',\n",
    "            'v2.1': 'CREATED_FILE, MODIFIED_REGISTRY only',\n",
    "            'v2.2': 'READ_FILE, DELETE_FILE, QUERY_REGISTRY, DELETE_REGISTRY',\n",
    "            'benefit': 'Captures Discovery phase (T1082, T1012) accurately'\n",
    "        },\n",
    "        {\n",
    "            'feature': 'Path Generalization',\n",
    "            'v2.1': 'Absolute paths (C:\\\\Users\\\\Admin\\\\...)',\n",
    "            'v2.2': 'Environment variables (%USER%, %TEMP%)',\n",
    "            'benefit': 'Enables cross-system graph fusion (FUSION phase)'\n",
    "        },\n",
    "        {\n",
    "            'feature': 'Process Compression',\n",
    "            'v2.1': 'Compress all duplicate processes',\n",
    "            'v2.2': 'Selective compression (skip focus_processes)',\n",
    "            'benefit': 'Preserves critical process details'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, imp in enumerate(improvements, 1):\n",
    "        print(f\"\\n{i}. {imp['feature']}\")\n",
    "        print(f\"   v2.1: {imp['v2.1']}\")\n",
    "        print(f\"   v2.2: {imp['v2.2']}\")\n",
    "        print(f\"   Benefit: {imp['benefit']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Compare statistics\n",
    "    print(\"\\nStatistical Comparison (T1112 Example):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    v21_stats = {\n",
    "        'nodes': 213,\n",
    "        'edges': 271,\n",
    "        'registry_nodes': 3,\n",
    "        'edge_types': ['CREATED', 'ACCESSED', 'CREATED_FILE', 'MODIFIED_REGISTRY']\n",
    "    }\n",
    "    \n",
    "    # Load v2.2 results\n",
    "    if results:\n",
    "        t1112_result = next((r for r in results if r['technique_id'] == 'T1112'), None)\n",
    "        if t1112_result:\n",
    "            v22_stats = t1112_result['stats']\n",
    "            \n",
    "            print(f\"Total Nodes:       v2.1={v21_stats['nodes']}, v2.2={v22_stats['total_nodes']}\")\n",
    "            print(f\"Total Edges:       v2.1={v21_stats['edges']}, v2.2={v22_stats['total_edges']}\")\n",
    "            print(f\"Registry Nodes:    v2.1={v21_stats['registry_nodes']}, v2.2={v22_stats['node_types'].get('Registry', 0)}\")\n",
    "            print(f\"Edge Types:        v2.1={len(v21_stats['edge_types'])}, v2.2={len(v22_stats['edge_types'])}\")\n",
    "            print(f\"Orphan Edges:      v2.1=0, v2.2={v22_stats['orphan_edges']}\")\n",
    "            print(f\"Isolated Nodes:    v2.1=0, v2.2={v22_stats['isolated_nodes']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "compare_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b2b1b",
   "metadata": {},
   "source": [
    "## Test: Verify Improvements on Sample Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68c59489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MultiKG v2.2 improvements on T1548.002...\n",
      "======================================================================\n",
      "\n",
      "v2.1 Stats (old): 234 nodes, 316 edges\n",
      "Expected v2.2: ~60-80 nodes (65% reduction)\n",
      "\n",
      "\n",
      "Processing T1548.002...\n",
      "Parsing windows-sysmon.log...\n",
      "Parsed 6715 events\n",
      "After filtering: 6497 events (removed 218 noise)\n",
      "Ancestry map: 252 parent-child relationships\n",
      "Attack subgraph: 321 events from 153 malicious processes\n",
      "[DEBUG] T1204.002: Adding synthetic cmd.exe execution for test.bat\n",
      "  Post-processing removed: 149 nodes, 164 edges\n",
      "    - Monitoring agents & subtrees\n",
      "    - Test artifacts (Write-Host patterns)\n",
      "    - Distant system processes\n",
      "    - Temporary files & setup noise\n",
      "\n",
      "Graph Statistics (after post-processing):\n",
      "  Nodes: 111\n",
      "  Edges: 99\n",
      "  Orphan Edges: 0\n",
      "  Isolated Nodes: 6\n",
      "  Node Types: {'Process': 89, 'Registry': 10, 'File': 10, 'Network': 2}\n",
      "  Edge Types: {'CREATED': 80, 'CREATED_FILE': 6, 'CONNECTED_TO': 2, 'MODIFIED_REGISTRY': 9, 'DELETE_REGISTRY': 2}\n",
      "Saved to d:\\nckh\\auditlog\\output\\T1548.002_graph_v2.2.json\n",
      "\n",
      "======================================================================\n",
      "v2.2 RESULTS:\n",
      "======================================================================\n",
      "Total Nodes: 111 (Reduction: 52.6%)\n",
      "Total Edges: 99 (Reduction: 68.7%)\n",
      "\n",
      "Node Distribution:\n",
      "  Process: 89\n",
      "  Registry: 10\n",
      "  File: 10\n",
      "  Network: 2\n",
      "\n",
      "Edge Types:\n",
      "  CREATED: 80\n",
      "  CREATED_FILE: 6\n",
      "  CONNECTED_TO: 2\n",
      "  MODIFIED_REGISTRY: 9\n",
      "  DELETE_REGISTRY: 2\n",
      "\n",
      "Quality Metrics:\n",
      "  Orphan Edges: 0 (Target: 0)\n",
      "  Isolated Nodes: 6 (Target: 0)\n",
      "\n",
      "======================================================================\n",
      "IMPROVEMENT VERIFICATION:\n",
      "======================================================================\n",
      "✓ No orphan edges\n",
      "✓ Self-loops removed\n",
      "✓ PSScriptPolicyTest artifacts filtered\n",
      "\n",
      "⚠ Only 3/5 improvements verified\n"
     ]
    }
   ],
   "source": [
    "# Test v2.2 improvements on T1548.002 (highest node count in v2.1)\n",
    "print(\"Testing MultiKG v2.2 improvements on T1548.002...\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nv2.1 Stats (old): 234 nodes, 316 edges\")\n",
    "print(\"Expected v2.2: ~60-80 nodes (65% reduction)\\n\")\n",
    "\n",
    "test_result = process_technique_v2_2('T1548.002', BASE_DIR, CONFIG_DIR, OUTPUT_DIR)\n",
    "\n",
    "if test_result:\n",
    "    stats = test_result['stats']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"v2.2 RESULTS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Nodes: {stats['total_nodes']} (Reduction: {((234 - stats['total_nodes']) / 234 * 100):.1f}%)\")\n",
    "    print(f\"Total Edges: {stats['total_edges']} (Reduction: {((316 - stats['total_edges']) / 316 * 100):.1f}%)\")\n",
    "    print(f\"\\nNode Distribution:\")\n",
    "    for node_type, count in stats['node_types'].items():\n",
    "        print(f\"  {node_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nEdge Types:\")\n",
    "    for edge_type, count in stats['edge_types'].items():\n",
    "        print(f\"  {edge_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nQuality Metrics:\")\n",
    "    print(f\"  Orphan Edges: {stats['orphan_edges']} (Target: 0)\")\n",
    "    print(f\"  Isolated Nodes: {stats['isolated_nodes']} (Target: 0)\")\n",
    "    \n",
    "    # Check for improvements\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"IMPROVEMENT VERIFICATION:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    improvements = []\n",
    "    if stats['total_nodes'] < 100:\n",
    "        improvements.append(\"✓ Node explosion fixed (< 100 nodes)\")\n",
    "    if stats['orphan_edges'] == 0:\n",
    "        improvements.append(\"✓ No orphan edges\")\n",
    "    if stats['isolated_nodes'] == 0:\n",
    "        improvements.append(\"✓ No isolated nodes\")\n",
    "    \n",
    "    # Check for self-loops in edges\n",
    "    graph = test_result['graph']\n",
    "    self_loops = [e for e in graph['edges'] if e['source'] == e['target']]\n",
    "    if len(self_loops) == 0:\n",
    "        improvements.append(\"✓ Self-loops removed\")\n",
    "    else:\n",
    "        print(f\"⚠ Warning: Found {len(self_loops)} self-loops\")\n",
    "    \n",
    "    # Check for PSScriptPolicyTest\n",
    "    ps_artifacts = [n for n in graph['nodes'] if 'PSScriptPolicyTest' in str(n.get('properties', {}))]\n",
    "    if len(ps_artifacts) == 0:\n",
    "        improvements.append(\"✓ PSScriptPolicyTest artifacts filtered\")\n",
    "    else:\n",
    "        print(f\"⚠ Warning: Found {len(ps_artifacts)} PSScriptPolicyTest nodes\")\n",
    "    \n",
    "    print(\"\\n\".join(improvements))\n",
    "    \n",
    "    if len(improvements) >= 4:\n",
    "        print(\"\\n✓ All major improvements verified successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Only {len(improvements)}/5 improvements verified\")\n",
    "else:\n",
    "    print(\"❌ Test failed - no results returned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
